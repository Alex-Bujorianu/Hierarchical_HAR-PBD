{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# For use with Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "%cd /content/drive/'My Drive'/'Colab Notebooks'/Hierarchical_HAR-PBD"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjacency matrix:  [[0. 1. 0. 0.]\n",
      " [1. 0. 1. 1.]\n",
      " [0. 1. 0. 1.]\n",
      " [0. 1. 1. 0.]]\n",
      "Classes before new encoding  [ 1.  2.  3.  4.  5.  6.  7.  9. 11. 14. 17. 18. 20. 21. 22. 23. 24. 25.\n",
      " 26. 27.]\n",
      "Classes after new encoding  [ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17. 18.]\n",
      "Classes in Y_train:  [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17.]\n",
      "Timestep:  120 Body num:  4 Num classes HAR:  18\n",
      "HARextend shape:  (None, 120, 4, 18)\n",
      "HAR temporal output1 shape:  (None, 18)\n",
      "PDB temporal output1 shape  (None, 2)\n",
      "Class counts:  (array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,\n",
      "       13., 14., 15., 16., 17.]), array([2595, 1728, 2295,  129,  456,  192,  252, 2208,  852,  831,   48,\n",
      "       2871,  144,  528, 2859,  435,  504,  384]))\n",
      "Epoch 1/100\n",
      "129/129 [==============================] - 24s 139ms/step - loss: 0.1038 - categorical_accuracy: 0.1239 - val_loss: 0.0904 - val_categorical_accuracy: 0.1392\n",
      "Epoch 2/100\n",
      " 96/129 [=====================>........] - ETA: 8s - loss: 0.0946 - categorical_accuracy: 0.1315"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [6], line 151\u001B[0m\n\u001B[1;32m    149\u001B[0m train \u001B[38;5;241m=\u001B[39m \u001B[38;5;28minput\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTrain model? Yes/no\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    150\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m train\u001B[38;5;241m==\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYes\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m--> 151\u001B[0m     model \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mHARmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mY_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mY_test\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    152\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    153\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLoading model…\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[0;32mIn [6], line 139\u001B[0m, in \u001B[0;36mtrain_model\u001B[0;34m(model, X_train, X_test, Y_train, Y_test)\u001B[0m\n\u001B[1;32m    126\u001B[0m \u001B[38;5;66;03m# print(\"Shape of categorically encoded Y_train: \", Y_train.shape)\u001B[39;00m\n\u001B[1;32m    127\u001B[0m \u001B[38;5;66;03m# print(\"Shape of categorically encoded Y_test: \", Y_test.shape)\u001B[39;00m\n\u001B[1;32m    128\u001B[0m \u001B[38;5;66;03m# Beta = 0.9999 produces a really small loss\u001B[39;00m\n\u001B[1;32m    129\u001B[0m model\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mcompile(optimizer\u001B[38;5;241m=\u001B[39mAdam(learning_rate\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5e-4\u001B[39m, decay\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1e-5\u001B[39m),\n\u001B[1;32m    130\u001B[0m               loss\u001B[38;5;241m=\u001B[39m{\n\u001B[1;32m    131\u001B[0m                     \u001B[38;5;66;03m# 'HARout': 'categorical_crossentropy'\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    136\u001B[0m               loss_weights\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mHARout\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m1.\u001B[39m},\n\u001B[1;32m    137\u001B[0m               metrics\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcategorical_accuracy\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m--> 139\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgraphtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    140\u001B[0m \u001B[43m          \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mY_train\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    141\u001B[0m \u001B[43m          \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m150\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    142\u001B[0m \u001B[43m          \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    143\u001B[0m \u001B[43m          \u001B[49m\u001B[38;5;66;43;03m#callbacks=utils.build_callbacks('Model', str(valid_patient)),\u001B[39;49;00m\n\u001B[1;32m    144\u001B[0m \u001B[43m          \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mgraphtest\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mY_test\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    145\u001B[0m \u001B[43m          \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    146\u001B[0m model\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39msave(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mModels/GC_LSTM_HAR\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    147\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m model\u001B[38;5;241m.\u001B[39mmodel\n",
      "File \u001B[0;32m~/gits/venv/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/gits/venv/lib/python3.10/site-packages/keras/engine/training.py:1564\u001B[0m, in \u001B[0;36mModel.fit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1556\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[1;32m   1557\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   1558\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1561\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[1;32m   1562\u001B[0m ):\n\u001B[1;32m   1563\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[0;32m-> 1564\u001B[0m     tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1565\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[1;32m   1566\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[0;32m~/gits/venv/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/gits/venv/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:915\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    912\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    914\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[0;32m--> 915\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    917\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[1;32m    918\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[0;32m~/gits/venv/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:947\u001B[0m, in \u001B[0;36mFunction._call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    944\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[1;32m    945\u001B[0m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[1;32m    946\u001B[0m   \u001B[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[0;32m--> 947\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_stateless_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# pylint: disable=not-callable\u001B[39;00m\n\u001B[1;32m    948\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stateful_fn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    949\u001B[0m   \u001B[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[1;32m    950\u001B[0m   \u001B[38;5;66;03m# in parallel.\u001B[39;00m\n\u001B[1;32m    951\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[0;32m~/gits/venv/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2496\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   2493\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[1;32m   2494\u001B[0m   (graph_function,\n\u001B[1;32m   2495\u001B[0m    filtered_flat_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_define_function(args, kwargs)\n\u001B[0;32m-> 2496\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2497\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfiltered_flat_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/gits/venv/lib/python3.10/site-packages/tensorflow/python/eager/function.py:1862\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[0;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[1;32m   1858\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[1;32m   1859\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[1;32m   1860\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[1;32m   1861\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[0;32m-> 1862\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_call_outputs(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1863\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcancellation_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcancellation_manager\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m   1864\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[1;32m   1865\u001B[0m     args,\n\u001B[1;32m   1866\u001B[0m     possible_gradient_type,\n\u001B[1;32m   1867\u001B[0m     executing_eagerly)\n\u001B[1;32m   1868\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[0;32m~/gits/venv/lib/python3.10/site-packages/tensorflow/python/eager/function.py:499\u001B[0m, in \u001B[0;36m_EagerDefinedFunction.call\u001B[0;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[1;32m    497\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _InterpolateFunctionError(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    498\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m cancellation_manager \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 499\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    500\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msignature\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    501\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_num_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    502\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    503\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    504\u001B[0m \u001B[43m        \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mctx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    505\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    506\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[1;32m    507\u001B[0m         \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msignature\u001B[38;5;241m.\u001B[39mname),\n\u001B[1;32m    508\u001B[0m         num_outputs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_outputs,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    511\u001B[0m         ctx\u001B[38;5;241m=\u001B[39mctx,\n\u001B[1;32m    512\u001B[0m         cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_manager)\n",
      "File \u001B[0;32m~/gits/venv/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     53\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[0;32m---> 54\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     55\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     56\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     57\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from Baseline.HierarchicalHAR_PBD import build_model\n",
    "import Baseline.utils as utils\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import h5py\n",
    "import os\n",
    "from helper import merge_option_1\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "tf.keras.utils.set_random_seed(42) # Sets it for TF, numpy and base Python\n",
    "from tensorflow.keras.layers import * # for the new versions of Tensorflow, layers, models, regularizers, and optimizers shall be imported from Tensorflow.\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.regularizers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from keras.losses import * # and losses, metrics, callbacks, and backend can still be used from Keras directly.\n",
    "from keras.metrics import *\n",
    "from keras import metrics\n",
    "from sklearn.metrics import *\n",
    "from keras import backend as K\n",
    "from keras.backend import *\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import TensorBoard\n",
    "from numpy.linalg import inv\n",
    "from scipy.linalg import fractional_matrix_power\n",
    "from keras.utils.np_utils import *\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score,accuracy_score\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "adjacency_matrix = np.zeros((4, 4))\n",
    "adjacency_matrix[0, 1] = 1\n",
    "adjacency_matrix[1, 0] = 1\n",
    "adjacency_matrix[1, 2] = 1\n",
    "adjacency_matrix[1, 3] = 1\n",
    "adjacency_matrix[2, 1] = 1\n",
    "adjacency_matrix[2, 3] = 1\n",
    "adjacency_matrix[3, 1] = 1\n",
    "adjacency_matrix[3, 2] = 1\n",
    "print(\"Adjacency matrix: \", adjacency_matrix)\n",
    "norm_adj = utils.MakeGraph(adjacency_matrix)\n",
    "\n",
    "class HAR_model_wrapper():\n",
    "    \"A class to hold a HAR model and its important properties\"\n",
    "    timestep = 0\n",
    "    node_num = 0\n",
    "    feature_num = 0\n",
    "    adjacency_matrix = None\n",
    "    num_classes = 0\n",
    "    def __init__(self, adjacency_matrix, timestep, node_num, feature_num, num_class_HAR=26):\n",
    "        assert adjacency_matrix.shape[0] == node_num\n",
    "        assert adjacency_matrix.shape[1] == node_num\n",
    "        self.model = build_model(timestep=timestep, body_num=node_num, feature_dim=feature_num,\n",
    "                              gcn_units_HAR=26, lstm_units_HAR=24, adjacency_matrix=adjacency_matrix,\n",
    "                              gcn_units_PBD=16, lstm_units_PBD=24,\n",
    "                              num_class_HAR=num_class_HAR, num_class_PBD=2)[1]\n",
    "        self.num_classes = num_class_HAR\n",
    "        self.timestep = timestep\n",
    "        self.node_num = node_num\n",
    "        self.feature_num = feature_num\n",
    "        self.adjacency_matrix = adjacency_matrix\n",
    "\n",
    "X_train = np.load(\"Data/X_train_pain.npy\")\n",
    "Y_train = np.load(\"Data/Y_train_pain.npy\")\n",
    "X_test = np.load(\"Data/X_test_pain.npy\")\n",
    "Y_test = np.load(\"Data/Y_test_pain.npy\")\n",
    "# Do not use the merge functions if you use this function\n",
    "# This function also implements merge option 1\n",
    "def new_encoding(arr: np.ndarray):\n",
    "    conversion_dict = {1: 1, 2:2, 3:3, 4:4, 5:5, 6:6, 7:7,\n",
    "                       9:8, 11:8, 14:9, 17:10, 18:11, 20:8,\n",
    "                       21:12, 22:13, 23:14, 24:15, 25:16, 26:17, 27:18}\n",
    "    for i in range(arr.shape[0]):\n",
    "        arr[i][0] = conversion_dict[arr[i][0]]\n",
    "print(\"Classes before new encoding \", np.unique(Y_train))\n",
    "new_encoding(Y_train)\n",
    "new_encoding(Y_test)\n",
    "print(\"Classes after new encoding \", np.unique(Y_train))\n",
    "result = np.matmul(norm_adj, X_train[0, 0, :, :])\n",
    "# print(\"Result of matrix multiplication of normalized adjacency matrix with \"\n",
    "#       \"4x3 matrix from X[0, 0]: \", result,\n",
    "#       \"and its shape: \", result.shape)\n",
    "\n",
    "#Tensorflow expects classes to start from 0, otherwise it throws a fit\n",
    "Y_train = Y_train - 1\n",
    "Y_test = Y_test - 1\n",
    "print(\"Classes in Y_train: \", np.unique(Y_train))\n",
    "\n",
    "class_counts = np.unique(Y_train, return_counts=True)\n",
    "# Add missing labels to class_counts\n",
    "def add_missing_labels(class_counts: tuple) -> tuple:\n",
    "    labels = class_counts[0]\n",
    "    counts = class_counts[1]\n",
    "    new_labels = np.array(list(range(0, 26)))\n",
    "    # Assume that the labels with 0 samples have 1 sample\n",
    "    # to avoid a divide by zero error\n",
    "    # the effect of this assumption is quite negligible\n",
    "    new_counts = np.ones(shape=(26,))\n",
    "    print(new_counts)\n",
    "    res = {new_labels[i]: new_counts[i] for i in range(len(new_labels))}\n",
    "    for i in range(len(labels)):\n",
    "        res[labels[i]] = counts[i]\n",
    "    return res\n",
    "\n",
    "# Now 27 labels\n",
    "HARmodel = HAR_model_wrapper(adjacency_matrix=adjacency_matrix,\n",
    "                             timestep=120, node_num=4, feature_num=3, num_class_HAR=18)\n",
    "\n",
    "\n",
    "def train_model(model: HAR_model_wrapper, X_train: np.ndarray, X_test: np.ndarray,\n",
    "                Y_train: np.ndarray, Y_test: np.ndarray):\n",
    "    AdjNorm = utils.MakeGraph(model.adjacency_matrix)\n",
    "    graphtrain = utils.my_combine(AdjNorm, X_train)\n",
    "    graphtest = utils.my_combine(AdjNorm, X_test)\n",
    "    # print(\"Shape of X train :\", X_train.shape)\n",
    "    # print(\"Shape of Y train before one-hot encoding: \", Y_train.shape)\n",
    "    class_counts = np.unique(Y_train, return_counts=True)\n",
    "    #class_counts = add_missing_labels(class_counts)\n",
    "    print(\"Class counts: \", class_counts)\n",
    "    # One hot encoding\n",
    "    Y_train = to_categorical(Y_train, num_classes=model.num_classes)\n",
    "    Y_test = to_categorical(Y_test, num_classes=model.num_classes)\n",
    "    # print(\"Shape of categorically encoded Y_train: \", Y_train.shape)\n",
    "    # print(\"Shape of categorically encoded Y_test: \", Y_test.shape)\n",
    "    # Beta = 0.9999 produces a really small loss\n",
    "    model.model.compile(optimizer=Adam(learning_rate=5e-4, decay=1e-5),\n",
    "                  loss={\n",
    "                        # 'HARout': 'categorical_crossentropy'\n",
    "                        'HARout': utils.focal_loss(weights = utils.class_balance_weights(0.30,\n",
    "                                     class_counts[1]),\n",
    "                                     gamma=5, num_class=model.num_classes)\n",
    "                        },\n",
    "                  loss_weights={'HARout': 1.},\n",
    "                  metrics=['categorical_accuracy'])\n",
    "\n",
    "    model.model.fit(x=graphtrain,\n",
    "              y=Y_train,\n",
    "              batch_size=150,\n",
    "              epochs=100,\n",
    "              #callbacks=utils.build_callbacks('Model', str(valid_patient)),\n",
    "              validation_data=(graphtest, Y_test)\n",
    "              )\n",
    "    model.model.save(\"Models/GC_LSTM_HAR\")\n",
    "    return model.model\n",
    "\n",
    "train = input(\"Train model? Yes/no\")\n",
    "if train==\"Yes\":\n",
    "    model = train_model(HARmodel, X_train, X_test, Y_train, Y_test)\n",
    "else:\n",
    "    print(\"Loading model…\")\n",
    "    model = keras.models.load_model(\"Models/GC_LSTM_HAR\")\n",
    "AdjNorm = utils.MakeGraph(HARmodel.adjacency_matrix)\n",
    "graphtest = utils.my_combine(AdjNorm, X_test)\n",
    "print(\"Y test before categorical encoding: \", Y_test.shape)\n",
    "predictions = model.predict(graphtest)\n",
    "print(\"Shape of predictions: \", predictions.shape)\n",
    "print(\"First predictions: \", predictions[0])\n",
    "# Do these numbers actually sum to 1?\n",
    "for i in range(predictions.shape[0]):\n",
    "    print(\"Sum: \", np.sum(predictions[0]))\n",
    "    break\n",
    "\n",
    "#Pretty much. So pick the most likely class\n",
    "def zeros_and_ones(arr):\n",
    "    to_return = np.zeros(shape=arr.shape[0])\n",
    "    for i in range(arr.shape[0]):\n",
    "        # print(\"Index of biggest number: \", np.argmax(arr[i]))\n",
    "        to_return[i] = np.argmax(arr[i])\n",
    "    return to_return\n",
    "\n",
    "# Transform predictions back to original shape\n",
    "predictions = zeros_and_ones(predictions)\n",
    "# Save results\n",
    "results = {\"F1 score\": f1_score(Y_test, predictions, average='weighted'),\n",
    "           \"Accuracy\": accuracy_score(Y_test, predictions),\n",
    "           \"Precision\": precision_score(Y_test, predictions, average='weighted'),\n",
    "           \"Recall\": recall_score(Y_test, predictions, average='weighted'),\n",
    "           \"Confusion matrix\": confusion_matrix(Y_test, predictions, labels=np.array(list(range(1, 20))))}\n",
    "print(\"F1 score \", f1_score(Y_test, predictions, average='weighted'))\n",
    "print(\"Accuracy \", accuracy_score(Y_test, predictions))\n",
    "print(\"Precision \", precision_score(Y_test, predictions, average='weighted'))\n",
    "print(\"Recall \", recall_score(Y_test, predictions, average='weighted'))\n",
    "name = input(\"Please name this experiment\")\n",
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return json.JSONEncoder.default(self, obj)\n",
    "json.dump(results, open(\"Results/Experiment_\" + name, \"w\"), cls=NumpyEncoder)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}