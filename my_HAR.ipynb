{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# For use with Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "%cd /content/drive/'My Drive'/'Colab Notebooks'/Hierarchical_HAR-PBD"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjacency matrix:  [[0. 1. 0. 0.]\n",
      " [1. 0. 1. 1.]\n",
      " [0. 1. 0. 1.]\n",
      " [0. 1. 1. 0.]]\n",
      "Classes before new encoding  [ 1.  2.  3.  4.  5.  6.  7.  9. 11. 14. 17. 18. 20. 21. 22. 23. 24. 25.\n",
      " 26. 27.]\n",
      "Classes after new encoding  [ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17. 18.]\n",
      "Classes in Y_train:  [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17.]\n",
      "Timestep:  120 Body num:  4 Num classes HAR:  18\n",
      "HARextend shape:  (None, 120, 4, 18)\n",
      "HAR temporal output1 shape:  (None, 18)\n",
      "PDB temporal output1 shape  (None, 2)\n",
      "Loading model…\n",
      "Y test before categorical encoding:  (1623, 1)\n",
      "51/51 [==============================] - 3s 26ms/step\n",
      "Shape of predictions:  (1623, 27)\n",
      "First predictions:  [1.0631919e-02 3.8984444e-04 1.7629491e-04 3.4513854e-04 2.3674742e-05\n",
      " 5.5801138e-05 2.6704129e-04 2.0816919e-06 1.0007266e-03 1.9678957e-06\n",
      " 1.3936927e-06 2.7557667e-06 2.3912942e-06 8.4199728e-06 1.5359890e-06\n",
      " 1.8786030e-06 8.3187880e-04 2.6487562e-05 2.6453845e-06 1.7843562e-06\n",
      " 4.5221518e-03 4.9669179e-04 2.0756795e-06 3.8552553e-05 2.4746332e-05\n",
      " 9.8079497e-01 3.4516343e-04]\n",
      "Sum:  1.0\n",
      "F1 score  0.0\n",
      "Accuracy  0.0\n",
      "Precision  0.0\n",
      "Recall  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/gits/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/alex/gits/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/alex/gits/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/alex/gits/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from Baseline.HierarchicalHAR_PBD import build_model\n",
    "import Baseline.utils as utils\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import h5py\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "tf.keras.utils.set_random_seed(42) # Sets it for TF, numpy and base Python\n",
    "from tensorflow.keras.layers import * # for the new versions of Tensorflow, layers, models, regularizers, and optimizers shall be imported from Tensorflow.\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.regularizers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from keras.losses import * # and losses, metrics, callbacks, and backend can still be used from Keras directly.\n",
    "from keras.metrics import *\n",
    "from keras import metrics\n",
    "from sklearn.metrics import *\n",
    "from keras import backend as K\n",
    "from keras.backend import *\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import TensorBoard\n",
    "from numpy.linalg import inv\n",
    "from scipy.linalg import fractional_matrix_power\n",
    "from keras.utils.np_utils import *\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score,accuracy_score\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from helper import max_scale\n",
    "import json\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] = 300\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "adjacency_matrix = np.zeros((4, 4))\n",
    "adjacency_matrix[0, 1] = 1\n",
    "adjacency_matrix[1, 0] = 1\n",
    "adjacency_matrix[1, 2] = 1\n",
    "adjacency_matrix[1, 3] = 1\n",
    "adjacency_matrix[2, 1] = 1\n",
    "adjacency_matrix[2, 3] = 1\n",
    "adjacency_matrix[3, 1] = 1\n",
    "adjacency_matrix[3, 2] = 1\n",
    "print(\"Adjacency matrix: \", adjacency_matrix)\n",
    "norm_adj = utils.MakeGraph(adjacency_matrix)\n",
    "\n",
    "class HAR_model_wrapper():\n",
    "    \"A class to hold a HAR model and its important properties\"\n",
    "    timestep = 0\n",
    "    node_num = 0\n",
    "    feature_num = 0\n",
    "    adjacency_matrix = None\n",
    "    num_classes = 0\n",
    "    def __init__(self, adjacency_matrix, timestep, node_num, feature_num, num_class_HAR=26):\n",
    "        assert adjacency_matrix.shape[0] == node_num\n",
    "        assert adjacency_matrix.shape[1] == node_num\n",
    "        self.model = build_model(timestep=timestep, body_num=node_num, feature_dim=feature_num,\n",
    "                              gcn_units_HAR=26, lstm_units_HAR=24, adjacency_matrix=adjacency_matrix,\n",
    "                              gcn_units_PBD=16, lstm_units_PBD=24,\n",
    "                              num_class_HAR=num_class_HAR, num_class_PBD=2)[1]\n",
    "        self.num_classes = num_class_HAR\n",
    "        self.timestep = timestep\n",
    "        self.node_num = node_num\n",
    "        self.feature_num = feature_num\n",
    "        self.adjacency_matrix = adjacency_matrix\n",
    "\n",
    "X_train = np.load(\"Data/X_train_pain.npy\")\n",
    "Y_train = np.load(\"Data/Y_train_pain.npy\")\n",
    "X_test = np.load(\"Data/X_test_pain.npy\")\n",
    "Y_test = np.load(\"Data/Y_test_pain.npy\")\n",
    "# Scale the data\n",
    "for i in range(X_train.shape[2]):\n",
    "    for j in range(X_train.shape[3]):\n",
    "        X_train[:, :, i, j] = max_scale(X_train[:, :, i, j])\n",
    "for i in range(X_test.shape[2]):\n",
    "    for j in range(X_test.shape[3]):\n",
    "        X_test[:, :, i, j] = max_scale(X_test[:, :, i, j])\n",
    "# Do not use the merge functions if you use this function\n",
    "# This function also implements merge option 1\n",
    "def new_encoding(arr: np.ndarray):\n",
    "    conversion_dict = {1: 1, 2:2, 3:3, 4:4, 5:5, 6:6, 7:7,\n",
    "                       9:8, 11:8, 14:9, 17:10, 18:11, 20:8,\n",
    "                       21:12, 22:13, 23:14, 24:15, 25:16, 26:17, 27:18}\n",
    "    for i in range(arr.shape[0]):\n",
    "        arr[i][0] = conversion_dict[arr[i][0]]\n",
    "print(\"Classes before new encoding \", np.unique(Y_train))\n",
    "new_encoding(Y_train)\n",
    "new_encoding(Y_test)\n",
    "print(\"Classes after new encoding \", np.unique(Y_train))\n",
    "result = np.matmul(norm_adj, X_train[0, 0, :, :])\n",
    "# print(\"Result of matrix multiplication of normalized adjacency matrix with \"\n",
    "#       \"4x3 matrix from X[0, 0]: \", result,\n",
    "#       \"and its shape: \", result.shape)\n",
    "\n",
    "#Tensorflow expects classes to start from 0, otherwise it throws a fit\n",
    "Y_train = Y_train - 1\n",
    "Y_test = Y_test - 1\n",
    "print(\"Classes in Y_train: \", np.unique(Y_train))\n",
    "\n",
    "class_counts = np.unique(Y_train, return_counts=True)\n",
    "# Add missing labels to class_counts\n",
    "def add_missing_labels(class_counts: tuple) -> tuple:\n",
    "    labels = class_counts[0]\n",
    "    counts = class_counts[1]\n",
    "    new_labels = np.array(list(range(0, 26)))\n",
    "    # Assume that the labels with 0 samples have 1 sample\n",
    "    # to avoid a divide by zero error\n",
    "    # the effect of this assumption is quite negligible\n",
    "    new_counts = np.ones(shape=(26,))\n",
    "    print(new_counts)\n",
    "    res = {new_labels[i]: new_counts[i] for i in range(len(new_labels))}\n",
    "    for i in range(len(labels)):\n",
    "        res[labels[i]] = counts[i]\n",
    "    return res\n",
    "\n",
    "# Now 27 labels\n",
    "HARmodel = HAR_model_wrapper(adjacency_matrix=adjacency_matrix,\n",
    "                             timestep=120, node_num=4, feature_num=3, num_class_HAR=18)\n",
    "\n",
    "\n",
    "def train_model(model: HAR_model_wrapper, X_train: np.ndarray, X_test: np.ndarray,\n",
    "                Y_train: np.ndarray, Y_test: np.ndarray):\n",
    "    AdjNorm = utils.MakeGraph(model.adjacency_matrix)\n",
    "    graphtrain = utils.my_combine(AdjNorm, X_train)\n",
    "    graphtest = utils.my_combine(AdjNorm, X_test)\n",
    "    # print(\"Shape of X train :\", X_train.shape)\n",
    "    # print(\"Shape of Y train before one-hot encoding: \", Y_train.shape)\n",
    "    class_counts = np.unique(Y_train, return_counts=True)\n",
    "    #class_counts = add_missing_labels(class_counts)\n",
    "    print(\"Class counts: \", class_counts)\n",
    "    # One hot encoding\n",
    "    Y_train = to_categorical(Y_train, num_classes=model.num_classes)\n",
    "    Y_test = to_categorical(Y_test, num_classes=model.num_classes)\n",
    "    # print(\"Shape of categorically encoded Y_train: \", Y_train.shape)\n",
    "    # print(\"Shape of categorically encoded Y_test: \", Y_test.shape)\n",
    "    # Beta = 0.9999 produces a really small loss\n",
    "    model.model.compile(optimizer=Adam(learning_rate=5e-4, decay=1e-5),\n",
    "                  loss={\n",
    "                        # 'HARout': 'categorical_crossentropy'\n",
    "                        'HARout': utils.focal_loss(weights = utils.class_balance_weights(0.30,\n",
    "                                     class_counts[1]),\n",
    "                                     gamma=5, num_class=model.num_classes)\n",
    "                        },\n",
    "                  loss_weights={'HARout': 1.},\n",
    "                  metrics=['categorical_accuracy'])\n",
    "\n",
    "    history = model.model.fit(x=graphtrain,\n",
    "              y=Y_train,\n",
    "              batch_size=150,\n",
    "              epochs=100,\n",
    "              #callbacks=utils.build_callbacks('Model', str(valid_patient)),\n",
    "              validation_data=(graphtest, Y_test)\n",
    "              )\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Loss over training epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    model.model.save(\"Models/GC_LSTM_HAR\")\n",
    "    return model.model\n",
    "\n",
    "train = input(\"Train model? Yes/no\")\n",
    "if train==\"Yes\":\n",
    "    model = train_model(HARmodel, X_train, X_test, Y_train, Y_test)\n",
    "else:\n",
    "    print(\"Loading model…\")\n",
    "    model = keras.models.load_model(\"Models/GC_LSTM_HAR\")\n",
    "AdjNorm = utils.MakeGraph(HARmodel.adjacency_matrix)\n",
    "graphtest = utils.my_combine(AdjNorm, X_test)\n",
    "print(\"Y test before categorical encoding: \", Y_test.shape)\n",
    "predictions = model.predict(graphtest)\n",
    "print(\"Shape of predictions: \", predictions.shape)\n",
    "print(\"First predictions: \", predictions[0])\n",
    "# Do these numbers actually sum to 1?\n",
    "for i in range(predictions.shape[0]):\n",
    "    print(\"Sum: \", np.sum(predictions[0]))\n",
    "    break\n",
    "\n",
    "#Pretty much. So pick the most likely class\n",
    "def zeros_and_ones(arr):\n",
    "    to_return = np.zeros(shape=arr.shape[0])\n",
    "    for i in range(arr.shape[0]):\n",
    "        # print(\"Index of biggest number: \", np.argmax(arr[i]))\n",
    "        to_return[i] = np.argmax(arr[i])\n",
    "    return to_return\n",
    "\n",
    "# Transform predictions back to original shape\n",
    "predictions = zeros_and_ones(predictions)\n",
    "# Save results\n",
    "results = {\"F1 score\": f1_score(Y_test, predictions, average='weighted'),\n",
    "           \"Accuracy\": accuracy_score(Y_test, predictions),\n",
    "           \"Precision\": precision_score(Y_test, predictions, average='weighted'),\n",
    "           \"Recall\": recall_score(Y_test, predictions, average='weighted'),\n",
    "           \"Confusion matrix\": confusion_matrix(Y_test, predictions, labels=np.array(list(range(1, 20))))}\n",
    "print(\"F1 score \", f1_score(Y_test, predictions, average='weighted'))\n",
    "print(\"Accuracy \", accuracy_score(Y_test, predictions))\n",
    "print(\"Precision \", precision_score(Y_test, predictions, average='weighted'))\n",
    "print(\"Recall \", recall_score(Y_test, predictions, average='weighted'))\n",
    "name = input(\"Please name this experiment\")\n",
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return json.JSONEncoder.default(self, obj)\n",
    "json.dump(results, open(\"Results/Experiment_\" + name, \"w\"), cls=NumpyEncoder)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}